{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2 Motion Planning with Potential Fields - Moving in the mall\n",
    "\n",
    "After implementing the SLAM algorithm, the robots provided by **<span style=\"color:seagreen\">UMA-MR</span>** are able to simultaneously build maps of the malls and localize themselves within them. However, the **<span style=\"color:seagreen\">managers at Nirvana</span>** are looking for a fully operational robot, and something is still missing: the navigation between any two points in the malls. These points could be, for example, an information point, a shop entrance or a shop counter, a rescue point, a restaurant, etc.\n",
    "\n",
    "From previous developments, our team has an algorithm able to find a sequence of waypoints between the start point and the goal one, that is, to plannify a **global navigation**. So **our mission here** is to develop an algorithm able to command the robot to safely navigate from a start waypoint to a (close) goal one, that is, to carry out **local reactive navigation**. \n",
    "\n",
    "The image below shows an sketch of the restaurants area in the **<span style=\"color:seagreen\">Nirvana mall</span>**, along with an example of global navigation (blue waypoints and dotted lines) between the information point and the *Dino's* restaurant. In that example, the green dotted lines correspond to the trajectory followed by a local reactive navigation avoiding obstacles in the waypoints path.\n",
    "\n",
    "<center><img src=\"images/mall_navigation_example2.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.1 Formalizing the problem\n",
    "\n",
    "The **reactive navigation** (or **local navigation**) has the objective of moving towards a close destination while avoiding obstacles. For that, it is available sensor data within a specific *look-ahed* as well as the goal point (**inputs**), being the reactive navigation method in charge of producing motor commands (**outputs**) to safely reach such goal.\n",
    "\n",
    "In this way, reactive navigation methods **does not require neither any kind of map of the environment nor memory of previous observations**. In practice, the last requirement usually arises since in some situations it could be useful to also consider the last sensor observations (e.g. while crossing a door).\n",
    "\n",
    "Finally, reactive navigation techniques **must run very fast** (i.e. real time or close to it) in order to safely reach the goal point. If not, dynamic obstacles or deprecated motion commands could lead the robot to crash!\n",
    "\n",
    "In summary: \n",
    "\n",
    "```\n",
    "reactive_navigation(current_location,target_location,sensor_readings)\n",
    "    # Method computations ... so fast!\n",
    "    return (v_l,v_r) # Motor actuation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.2 Potential Fields\n",
    "\n",
    "**Potential Fields** is a popular and simple technique for carrying out reactive navigation. Imagine the robot and the objects in its environment (like obstacles, the goal, etc.) are surrounded by invisible fields, similar to magnetic fields around magnets. These fields exert virtual forces on the robot, guiding its movement.\n",
    "\n",
    "To do this, it consist of defining a **potential (energy) function** over the free space in the robot workspace, which has a **global minimum** at the goal and a maximum at obstacles. Then, in each iteration of the algorithm, the robot moves to a lower energy configuration, similar to a a ball rolling down a hill. To carry out such navigation the robot applies a force proportional to the **negated gradient of the potential field** (recall that the gradient always go in the direction in which the signal increases, and the robot pursues a lower energy, so it has to use the negated gradient).\n",
    "\n",
    "The **potential (energy) function** defines a **potential field** over the workspace. For each robot position $p$ in such workspace, the energy function is computed as:\n",
    "\n",
    "$$U(p)=U_{att}(p)+U_{rep}(p)$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $U_{att}(p)$ is the **atractive potential field** representing the squared Euclidean distance to the goal, which is retrieved by:\n",
    "\n",
    "  $$U_{att}(p)=\\frac{1}{2}K_{att}d^2_{goal}(p)$$\n",
    "\n",
    "  being $d_{goal}$ said distance from the robot to the goal: $d^2_{goal}(p)=||p-p_{goal}||^2$ and $K_{att}$ a given gain, so this potential is higher for far distances, \n",
    "  <br />\n",
    "  \n",
    "- and $U_{rep}(q)$ is the **repulsive potential field**, which generates a barrier around obstacles, computed as:\n",
    " \n",
    " $$U_{rep}(p)=  \\begin{cases} \n",
    "   \\frac{1}{2} K_{rep}(\\frac{1}{d(p)}-\\frac{1}{d_{max}})^2 & \\text{if } d(p) \\leq d_{max} \\\\\n",
    "   0       & \\text{if } d(p) > d_{max}\n",
    "  \\end{cases}$$\n",
    "  \n",
    "  being $d_{max}$ a given distance threshold, so obstacles far away from the robot does not influence the potential field, and $d(p)$ the distance from the robot to the object so $d^2(p)=||p-p_{obj}||^2$.\n",
    "\n",
    "Having defined such potential field, it can be computed a **force field** at the robot position $F(p)$ (a two-element vector) as the gradient of the previous one:\n",
    "\n",
    "$$\n",
    "F(q) = -\\nabla U(p) = -\\nabla U_{att}(p) - \\nabla U_{rep}(p) = \\begin{bmatrix} \\partial U / \\partial x \\\\ \\partial U / \\partial y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $F_{att}(p)=-\\nabla U_{att}(p)$ is also called the **attractive force** and \n",
    "- $F_{rep}(p)=-\\nabla U_{rep}(p)$ the **repulsive force**, so\n",
    "- $F(p)=F_{att}(p)+F_{rep}(p)$. \n",
    "\n",
    "Finally, the **robot speed $[v_x,v_y]$** is set proportional to the force $F(p)$ as generated by the field.\n",
    "\n",
    "The picture below illustrates all the elements in the computation of $F(p)$ ($F_{total}$ in the image, colored as a red arrow):\n",
    "\n",
    "<center><img src=\"images/potential_fields.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.3 Developing the Potential Fields method for Reactive navigation\n",
    "\n",
    "It's time to develop our own Potential Fields method! For that, you first need to obtain the sum of the forces that apply at a certain robot position, computing for that the attractive and repulsive forces. Then, the total force can be retrieved, and it can be used to apply velocities to the robot wheels! (recall that $F(p)=F_{att}(p)+F_{rep}(p)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import linalg\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.DrawRobot import DrawRobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Computing the repulsive force</i></b></span>** \n",
    "\n",
    "Let's start with the repulsive force (`FRep`) computation, which is the sum of the repulsive forces yielded by each obstacle close to the object. Recall that forces are 2-elements column vectors. \n",
    "\n",
    "The `repulsive_force()` function below partially implements this computation. Notice that this function also plots a marker over the obstacles that have influence on this force, and store the handler of that plot in `hInfluentialObstacles`.\n",
    "\n",
    "Recall that:\n",
    "\n",
    "$$\n",
    "f_i=  \\begin{cases} \n",
    "   (\\frac{1}{d_i(p)}-\\frac{1}{d_{max}}) \\frac{1}{d_i(p)^2} \\frac{p-p_{i}}{d_i(p)} & \\text{if } d_i(p) \\leq d_{max} \\\\\n",
    "   0       & \\text{if } d_i(p) > d_{max}\n",
    "  \\end{cases}\n",
    "  \\\\\n",
    "F_{rep}(p) = K_{rep} \\sum_i f_i  \n",
    "$$\n",
    "\n",
    "In the code below, $p-p_{i}$ is stored in `p_to_object`, and $d(p)$ in `d`. Notice that for each $f_i$, the distance from the robot to the object $d_i(p)$ is a number, while $p-p_{i}$ is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repulsive_force(xRobot, Map, RadiusOfInfluence, KObstacles):\n",
    "    \"\"\" Computes the respulsive force at a given robot position\n",
    "    \n",
    "        Args:\n",
    "            xRobot: Column vector containing the robot position ([x,y]')\n",
    "            Map: Matrix containing the obstacles coordinates (size 2xN_obstacles)\n",
    "            RadiusOfInfluence: distance threshold for considering that an obstacle has influence\n",
    "            KObstacles: gain related to the repulsive force\n",
    "        \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "            Frep: repulsive force ([rf_x, rf_y]') (Column vector!)\n",
    "            hInfluentialObstacles: handler of the plot marking the obstacles that have influence\n",
    "    \"\"\"        \n",
    "    p_to_object = xRobot - Map\n",
    "    d = np.sqrt(np.sum(p_to_object**2, axis=0))\n",
    "    iInfluential = np.where(d <= RadiusOfInfluence)[0]\n",
    "    \n",
    "    if iInfluential.shape[0] > 0:\n",
    "        p_to_object = p_to_object[:, iInfluential]\n",
    "        d = d[iInfluential]\n",
    "        FRep = KObstacles * np.vstack([np.sum((1/d - 1/RadiusOfInfluence) * (1/d**2) * (p_to_object[0,:]/d)), np.sum((1/d - 1/RadiusOfInfluence) * (1/d**2) * (p_to_object[1,:]/d))])\n",
    "        \n",
    "        hInfluentialObstacles = plt.plot(Map[0,iInfluential],Map[1,iInfluential],'kx')\n",
    "    else:\n",
    "        # Nothing close\n",
    "        FRep = 0\n",
    "        hInfluentialObstacles = None # Don't touch this! It is ok :)\n",
    "    \n",
    "    return FRep, hInfluentialObstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repulsive force:\n",
      " [[ -7117.97589183]\n",
      " [-14205.83001107]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "xRobot = np.vstack([[1],[2]])\n",
    "Map = np.vstack([[1.1, 2.4, 3.5],[2.2, 1.4, 4.5]])\n",
    "RadiusOfInfluence = 2\n",
    "KObstacles = 200\n",
    "\n",
    "FRep, handler = repulsive_force(xRobot, Map, RadiusOfInfluence, KObstacles)\n",
    "\n",
    "print ('Repulsive force:\\n ' + str(FRep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "Repulsive force:\n",
    " [[ -7117.97589183]\n",
    " [-14205.83001107]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Retrieving the attractive force</i></b></span>** \n",
    "\n",
    "Next, **you need to compute** the Attractive Force `FAtt`. Do it in the `attractive_force()` function below, taking into account that:\n",
    "\n",
    "$$F_{att}(p)=-K_{att}d_{goal}(p)$$\n",
    "\n",
    "Normalize the resultant Force by $||\\Delta_{goal}||$ so its doesn't become too dominant. You can take a look at [linalg.norm()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html) for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attractive_force(KGoal, GoalError):\n",
    "    \"\"\" Computes the attractive force at a given robot position\n",
    "    \n",
    "        Args:\n",
    "            KGoal: gain related to the attractive force\n",
    "            GoalError: distance from the robot to the goal ([d_x d_y]')\n",
    "        \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "            FAtt: attractive force ([af_x, af_y]')\n",
    "    \"\"\"           \n",
    "    FAtt = -KGoal * GoalError\n",
    "    FAtt /= np.linalg.norm(GoalError) # Normalization\n",
    "    \n",
    "    return FAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attractive force:\n",
      " [[-1.28129783]\n",
      " [-0.77992042]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "KGoal = 1.5\n",
    "GoalError = np.vstack([[2.3],[1.4]]) \n",
    "\n",
    "FAtt = attractive_force(KGoal, GoalError)\n",
    "\n",
    "print ('Attractive force:\\n ' + str(FAtt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "Attractive force:\n",
    " [[-1.28129783]\n",
    " [-0.77992042]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Concluding with the Total Force</i></b></span>** \n",
    "\n",
    "Finally you can compute the Total Force `FTotal`. **Do it in the main program below**, considering that:\n",
    "\n",
    "$$\n",
    "F(p)=F_{att}(p)+F_{rep}(p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(nObstacles=175,\n",
    "         MapSize=100,\n",
    "         RadiusOfInfluence=10,\n",
    "         KGoal=1,\n",
    "         KObstacles=250,\n",
    "         nMaxSteps=300,\n",
    "         NON_STOP=True):\n",
    "    \n",
    "    Map = MapSize*random.rand(2, nObstacles)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()\n",
    "    ax.plot(Map[0,:],Map[1,:],'ro', fillstyle='none');\n",
    "    \n",
    "    fig.suptitle('Click to choose starting point:')\n",
    "    xStart = np.vstack(plt.ginput(1)).T\n",
    "    print('Starts at:\\n{}'.format(xStart))\n",
    "    \n",
    "    \n",
    "    fig.suptitle('Click to choose end goal:')\n",
    "    xGoal = np.vstack(plt.ginput(1)).T\n",
    "    print('Goal at:\\n{}'.format(xGoal))\n",
    "\n",
    "    fig.suptitle('')\n",
    "\n",
    "    ax.plot(xGoal[0, 0], xGoal[1, 0],'g*', markersize=10)\n",
    "    \n",
    "    hRob = DrawRobot(fig, ax, np.vstack([xStart, 0]), axis_percent=0.001, color='blue')\n",
    "    \n",
    "    # Initialization of useful vbles\n",
    "    xRobot = xStart\n",
    "    GoalError = xRobot - xGoal\n",
    "    \n",
    "    # Simulation\n",
    "    k = 0\n",
    "\n",
    "    while linalg.norm(GoalError) > 1 and k < nMaxSteps:\n",
    "\n",
    "        FRep, hInfluentialObstacles = repulsive_force(xRobot, Map, RadiusOfInfluence, KObstacles)\n",
    "        FAtt = attractive_force(KGoal, GoalError)\n",
    "                \n",
    "        # Point 1.3\n",
    "        # TODO Compute total (attractive+repulsive) potential field\n",
    "\n",
    "        FTotal = FAtt + FRep\n",
    "        #FTotal /= linalg.norm(FTotal)\n",
    "        \n",
    "        \n",
    "        xRobot += FTotal\n",
    "        Theta = np.arctan2(FTotal[1, 0], FTotal[0, 0])\n",
    "        \n",
    "        hRob.pop(0).remove()\n",
    "        hRob = DrawRobot(fig, ax, np.vstack([xRobot, Theta]), axis_percent=0.001, color='blue')\n",
    "        \n",
    "        if NON_STOP:\n",
    "            plt.pause(0.1)\n",
    "        else:\n",
    "            plt.waitforbuttonpress(-1)\n",
    "            \n",
    "        if hInfluentialObstacles is not None:\n",
    "            hInfluentialObstacles.pop(0).remove()\n",
    "        \n",
    "        # Update termination conditions\n",
    "        GoalError =  xRobot - xGoal\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.4 Understanding how the technique performs\n",
    "\n",
    "As a brilliant engineer, you have to provide some indications to the **<span style=\"color:seagreen\">managers at Nirvana</span>** about how the technique performs and its limitations, which has to be provided in the next <font color=\"blue\"><b><i>Thinking about it</i></b></font>. The following code cells help you to execute the implemented technique with different parameters in order to retrieve the required information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For considering different gains\n",
    "main(KGoal=1, KObstacles=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For considering different number of obstacles\n",
    "main(nObstacles=175)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "**Address the following points** to gain insight into how the developed Potential Fields technique performs. You can include some figures if needed.\n",
    "\n",
    "- Discuss the meaning of each element appearing in the plot during the simulation of the *Potential Fields reactive navigation*. $\\\\[10pt]$\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig8-1-2.png\" width=\"400\" alt=\"\" />\n",
    "</figure>\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Los puntos rojos son los obstáculos representados en el mapa (que es el espacio bidimensional mostrado en la gráfica). La pose de nuestro robot está representado con el triángulo azul y el recorrido que realiza deja una estela del mismo color. Su objetivo (meta) es la estrella verde. Cuando un obstáculo entra en el rango de consideración de la fuerza repulsiva, aparece tachado con una equis negra.</i></p>\n",
    "\n",
    "- Run the program setting different start and goal positions. Now change the values of the goal and obstacle gains (`KGoal` and `KObstacles`). How does this affect the paths followed by the robot?\n",
    "\n",
    "  Examples with different values for such constants:\n",
    "\n",
    "  <table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/fig8-1-3.png\" width=\"300\"></td>\n",
    "        <td><img src=\"images/fig8-1-4.png\" width=\"300\"></td>\n",
    "    </tr>\n",
    "  </table>\n",
    "  \n",
    "  <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>El valor de KObstacles determina la fuerza con la que los obstáculos obligan al robot a apartarse de ellos. Si esta fuerza es pequeña, el robot se acercará más a ellos (con el riesgo que eso conlleva) pero será capaz de pasar por caminos que no podría hacer si fuera elevada. Tener una fuerza de repulsión elevada minimiza el riesgo de chocarnos, pero favorece los estancamientos en los estrechamientos.</i></p>\n",
    "  <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Por otro lado, KGoal representa la fuerza con la que el objetivo tira del robot para que se aproxime, por lo que a valores elevados nuestro robot se acercará de manera más acelerada (más rápido y directo) hacia el mismo.</i></p>\n",
    "  \n",
    "- Play with different numbers of obstacles and discuss the obtained results.\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>En el caso de tener pocos obstáculos, el robot podrá llegar al objetivo sin tener que realizar muchas variaciones relevantes en su trayectoria y muy probablemente llegue hasta él. Puede darse el caso que tenga obstáculos en la línea recta que une la salida con la meta, o que tenga obstáculos a su alrededor y entren en la zona de consideración de la fuerza repulsiva, por lo que tendrá que variar su ruta.</i></p>\n",
    "    \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Si por el contrario tenemos demasiados obstáculos, aumentan las probabilidades de que se encuentre un mínimo local y nuestro robot se estanque en una posición que no es la meta. De igual manera, podemos ver que tiene que realizar muchos más cambios en su trayectoria y puede no llegar a la meta.</i></p>\n",
    "    \n",
    "- Illustrate a navigation where the robot doesn't reach the goal position in the specified number of steps. Why did that happen? Could the robot have reached the goal with more iterations of the algorithm? Hint: take a look at the ``FTotal`` variable.\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Como se ha comentado antes, puede darse el caso de estancamiento del robot a causa de las fuerzas repulsivas y atractivas que se ejercen sobre el robot. Esta sumatoria de fuerzas está almacenada en FTotal y como podemos comprobar no varía una vez el robot se ha estancado, por lo que da igual si dejamos el algoritmo más iteraciones que no se va poder mover el robot (aunque podríamos darle un empujón en alguna dirección aletoria para ver si consigue escapar).</i></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
